{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9506bbbc",
   "metadata": {},
   "source": [
    "### importing libaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d314de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import matplotlib as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import warnings\n",
    "from scipy import stats\n",
    "from scipy.signal import welch\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2519bf82",
   "metadata": {},
   "source": [
    "### Data Preparation: Combining Subject Files\n",
    "\n",
    "Our goal is **person identification** (creating a \"brainprint\") rather than \"task classification.\" Because of this, our data preparation strategy is different from a typical motor imagery analysis.\n",
    "\n",
    "#### 1. Ignoring `.event` Files\n",
    "\n",
    "* **Why:** The `.event` files only contain markers for *what* task the subject was performing (e.g., \"imagined left hand,\" \"rest\").\n",
    "* **Our Goal:** For this project, the **label is the person** (e.g., `S001`, `S002`), not the task. We don't care *what* they were doing; we only care *who* they are.\n",
    "* **Action:** All `.event` files were ignored. We only used the `.edf` (data) files.\n",
    "\n",
    "#### 2. Combining (Concatenating) `.edf` Files\n",
    "\n",
    "* **What:** For each subject, we loaded all 14 of their `.edf` files (from `R01` to `R14`).\n",
    "* **Why:** We want to create one single, long recording for each person. This provides a robust \"signature\" of their brain activity across various states (resting, task-focused, etc.).\n",
    "* **Action:** We used `mne.concatenate_raws()` to \"stitch\" the 14 files together, end-to-end, into one MNE `Raw` object per subject.\n",
    "\n",
    "#### 3. Resampling to a Common Frequency (128 Hz)\n",
    "\n",
    "* **Problem:** The dataset is inconsistent. Some files (especially for subjects 89+) were recorded at 160 Hz, while others were recorded at 128 Hz. MNE cannot concatenate files with different sampling frequencies (`sfreq`).\n",
    "* **Solution:** We resampled *every* file to a common frequency of **128.0 Hz** *before* concatenating them.\n",
    "* **Action:** This was done using `raw.resample(128.0)` right after loading each `.edf` file.\n",
    "\n",
    "#### 4. Saving the Combined Files\n",
    "\n",
    "* **Action:** The final, combined `Raw` object for each subject was saved as a `.fif` file (e.g., `S001_combined_raw.fif`).\n",
    "* **Why:** The `.fif` format is native to MNE and is much more efficient to load in our future notebooks than re-loading and re-combining all 14 `.edf` files every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893cb292",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_data_path = r'd:\\EEG\\1.0.0'\n",
    "total_subjects = 109\n",
    "COMMON_SFREQ = 128.0\n",
    "for i in range(1, total_subjects + 1):\n",
    "    subject_name = f'S{i:03d}'\n",
    "    subject_folder = os.path.join(base_data_path, subject_name)   \n",
    "    run_files = glob(os.path.join(subject_folder, f'{subject_name}R*.edf'))\n",
    "    run_files.sort()   \n",
    "    raws_list = []\n",
    "    print(f\"Found {len(run_files)} files. Loading and resampling...\")\n",
    "    for file_path in run_files:\n",
    "        raw = mne.io.read_raw_edf(file_path, preload=True)\n",
    "        \n",
    "        if raw.info['sfreq'] != COMMON_SFREQ:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                raw.resample(COMMON_SFREQ)\n",
    "        raws_list.append(raw)\n",
    "    combined_raw = mne.concatenate_raws(raws_list)\n",
    "    output_filename = os.path.join(subject_folder, f'{subject_name}_combined_raw.fif')\n",
    "    combined_raw.save(output_filename, overwrite=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a92d140",
   "metadata": {},
   "source": [
    "## Step 2: Apply Preprocessing Pipeline\n",
    "\n",
    "In this step, we loop through every subject's combined `.fif` file and apply our core preprocessing pipeline.\n",
    "\n",
    "The pipeline consists of:\n",
    "1.  **Loading** the combined file (e.g., `S001_combined_raw.fif`).\n",
    "2.  **Band-pass Filtering:** Keeping only the 1 Hz to 40 Hz frequency range, which contains the most relevant brain activity and removes slow drifts and high-frequency noise.\n",
    "3.  **Notch Filtering:** Removing the 50 Hz power-line interference.\n",
    "4.  **Re-referencing:** Setting the reference to the \"Common Average Reference\" (CAR) to remove widespread noise.\n",
    "5.  **Saving:** Saving the newly cleaned data to a new file (e.g., `S001_preprocessed_raw.fif`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0101d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_subjects = 109\n",
    "for i in range(1, total_subjects + 1):\n",
    "    subject_name = f'S{i:03d}'\n",
    "    file_path = os.path.join(base_data_path, subject_name, f'{subject_name}_combined_raw.fif')\n",
    "    raw = mne.io.read_raw_fif(file_path, preload=True)\n",
    "    # Filter\n",
    "    raw.filter(1.0, 40.0, method='fir', fir_design='firwin')\n",
    "    # Notch filter\n",
    "    raw.notch_filter(50.0, method='spectrum_fit')\n",
    "    # Re-referencing\n",
    "    raw.set_eeg_reference(ref_channels='average')\n",
    "    # Save the preprocessed data\n",
    "    output_path = os.path.join(base_data_path, subject_name, f'{subject_name}_preprocessed_raw.fif')\n",
    "    raw.save(output_path, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a258e012",
   "metadata": {},
   "source": [
    "## Step 3: Epoching the Preprocessed Data\n",
    "\n",
    "Now that we have 109 clean, continuous files, we need to chop them into small, uniform \"samples\" (called **epochs**) that we can feed into a Deep learning model.\n",
    "\n",
    "This code will:\n",
    "1.  Create a new central directory named `epochs_data` to store all the final epoch files.\n",
    "2.  Loop through each of the 109 `_preprocessed_raw.fif` files.\n",
    "3.  Manually \"chop\" the data into **2-second** long epochs.\n",
    "4.  Use a **50% overlap** (1 second). This is a data augmentation technique that gives us twice as many epochs (e.g., 0-2s, 1-3s, 2-4s, etc.).\n",
    "5.  Save these epochs as a NumPy array (`.npy` file) in the `epochs_data` folder.\n",
    "\n",
    "We are converting our data from the MNE `.fif` format into a pure NumPy array format, which is the standard for most machine learning libraries.\n",
    "\n",
    "### How it Works\n",
    "\n",
    "The code uses two functions:\n",
    "\n",
    "* **`create_fixed_length_epochs(...)`**: This is the \"worker\" function. It takes a single `raw` file and performs the manual sliding window logic. It extracts a 2-second chunk, moves forward 1 second, extracts the next chunk, and so on.\n",
    "* **`create_epochs_all_subjects(...)`**: This is the \"manager\" function. It loops through all 109 subjects, loads the preprocessed file for each one, and calls the \"worker\" function to create and save the epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8dadee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_epochs_all_subjects(base_data_path, total_subjects=109):\n",
    "    \"\"\"\n",
    "    Create epochs for all 109 subjects\n",
    "    \"\"\"\n",
    "    epochs_dir = os.path.join(base_data_path, 'epochs_data')\n",
    "    os.makedirs(epochs_dir, exist_ok=True)\n",
    "    for i in range(1, total_subjects + 1):\n",
    "        subject_name = f'S{i:03d}'\n",
    "        input_path = os.path.join(base_data_path, subject_name, f'{subject_name}_preprocessed_raw.fif')\n",
    "        output_path = os.path.join(epochs_dir, f'{subject_name}_epochs.npy')     \n",
    "        raw = mne.io.read_raw_fif(input_path, preload=True)\n",
    "        epochs = create_fixed_length_epochs(raw)\n",
    "        np.save(output_path, epochs)\n",
    "\n",
    "def create_fixed_length_epochs(raw, epoch_duration=2.0, overlap=0.5, sfreq=128.0):\n",
    "    \"\"\"\n",
    "    Create epochs with 2s duration and 50% overlap\n",
    "    \"\"\"\n",
    "    epoch_length = int(epoch_duration * sfreq)\n",
    "    overlap_samples = int(overlap * epoch_length)\n",
    "    step_size = epoch_length - overlap_samples\n",
    "    \n",
    "    data = raw.get_data()\n",
    "    n_channels, n_times = data.shape\n",
    "    \n",
    "    epochs = []\n",
    "    start = 0\n",
    "    \n",
    "    while start + epoch_length <= n_times:\n",
    "        epoch = data[:, start:start + epoch_length]\n",
    "        epochs.append(epoch)\n",
    "        start += step_size\n",
    "    \n",
    "    return np.array(epochs)\n",
    "\n",
    "\n",
    "create_epochs_all_subjects(base_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ce4eac",
   "metadata": {},
   "source": [
    "## Step 4: Feature Extraction\n",
    "\n",
    "This is the final step in our data preparation pipeline. We will convert the 2D epoch data (64 channels x 256 time points) into a 1D \"feature vector\" that a machine learning model can understand.\n",
    "\n",
    "This script will:\n",
    "1.  Create a new directory, `features_data`, to store our final dataset.\n",
    "2.  Loop through each subject's `_epochs.npy` file.\n",
    "3.  For each 2-second epoch, it will calculate a list of statistical features.\n",
    "4.  Crucially, it **creates the labels (`y`)**. For every epoch from subject `S001`, it assigns the label `1`. For `S002`, it assigns `2`, and so on.\n",
    "5.  It saves two final files:\n",
    "    * `X_features.npy`: A single, massive 2D array containing all features from all epochs from all subjects.\n",
    "    * `y_labels.npy`: A single, 1D array containing the corresponding subject label for each epoch.\n",
    "\n",
    "These two files, `X` and `y`, are the only things we need for training our \"brainprint\" classifier.\n",
    "\n",
    "### What Features Are Extracted?\n",
    "\n",
    "The code extracts **20 features** from *each* of the 64 channels and concatenates them into one long vector.\n",
    "\n",
    "**20 features/channel * 64 channels = 1280 total features per epoch.**\n",
    "\n",
    "The 20 features are:\n",
    "\n",
    "* **10 Time-Domain Features:**\n",
    "    1.  Mean\n",
    "    2.  Standard Deviation\n",
    "    3.  Median\n",
    "    4.  Minimum\n",
    "    5.  Maximum\n",
    "    6.  Peak-to-Peak (Max - Min)\n",
    "    7.  Mean Absolute Value\n",
    "    8.  Skewness\n",
    "    9.  Kurtosis\n",
    "    10. Root Mean Square (RMS)\n",
    "\n",
    "* **10 Frequency-Domain Features** (Calculated using Welch's PSD):\n",
    "    1.  Delta Band Power (0.5-4 Hz)\n",
    "    2.  Theta Band Power (4-8 Hz)\n",
    "    3.  Alpha Band Power (8-13 Hz)\n",
    "    4.  Beta Band Power (13-30 Hz)\n",
    "    5.  Gamma Band Power (30-40 Hz)\n",
    "    6.  Mean PSD\n",
    "    7.  Std Deviation of PSD\n",
    "    8.  Median PSD\n",
    "    9.  Dominant Frequency (freq with max power)\n",
    "    10. Maximum PSD value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e624bad3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'base_data_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 128\u001b[39m\n\u001b[32m    125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m features\n\u001b[32m    127\u001b[39m \u001b[38;5;66;03m# Run feature extraction for all subjects\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m X, y = extract_features_all_subjects(\u001b[43mbase_data_path\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'base_data_path' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy import stats\n",
    "from scipy.signal import welch\n",
    "\n",
    "def extract_features_all_subjects(base_data_path, total_subjects=109):\n",
    "    \"\"\"\n",
    "    Extract features from epochs for all 109 subjects\n",
    "    \"\"\"\n",
    "    epochs_dir = os.path.join(base_data_path, 'epochs_data')\n",
    "    features_dir = os.path.join(base_data_path, 'features_data')\n",
    "    os.makedirs(features_dir, exist_ok=True) \n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for i in range(1, total_subjects + 1):\n",
    "        subject_name = f'S{i:03d}'\n",
    "        epochs_path = os.path.join(epochs_dir, f'{subject_name}_epochs.npy')\n",
    "        features_path = os.path.join(features_dir, f'{subject_name}_features.npy')\n",
    "        labels_path = os.path.join(features_dir, f'{subject_name}_labels.npy')\n",
    " \n",
    "        # Load epochs\n",
    "        epochs = np.load(epochs_path)\n",
    "        \n",
    "        # Extract features\n",
    "        features = extract_features_from_epochs(epochs)\n",
    "        \n",
    "        # Create labels (subject ID)\n",
    "        labels = np.full(len(features), i)  # Label with subject number\n",
    "        \n",
    "        # Save features and labels for this subject\n",
    "        np.save(features_path, features)\n",
    "        np.save(labels_path, labels)\n",
    "        \n",
    "        # Collect for combined dataset\n",
    "        all_features.append(features)\n",
    "        all_labels.append(labels)\n",
    "    \n",
    "    # Combine all data\n",
    "    X = np.vstack(all_features)\n",
    "    y = np.hstack(all_labels)\n",
    "    \n",
    "    # Save combined dataset\n",
    "    np.save(os.path.join(features_dir, 'X_features.npy'), X)\n",
    "    np.save(os.path.join(features_dir, 'y_labels.npy'), y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def extract_features_from_epochs(epochs, sfreq=128.0):\n",
    "    \"\"\"\n",
    "    Extract features from epochs (shape: n_epochs × 64 channels × 256 time points)\n",
    "    \"\"\"\n",
    "    features_list = []\n",
    "    \n",
    "    for epoch in epochs:\n",
    "        # epoch shape: (64 channels × 256 time points)\n",
    "        epoch_features = []\n",
    "        \n",
    "        for channel_data in epoch:\n",
    "            # Extract features for each channel\n",
    "            channel_features = extract_channel_features(channel_data, sfreq)\n",
    "            epoch_features.extend(channel_features)\n",
    "        \n",
    "        features_list.append(epoch_features)\n",
    "    \n",
    "    return np.array(features_list)\n",
    "\n",
    "def extract_channel_features(channel_data, sfreq=128.0):\n",
    "    \"\"\"\n",
    "    Extract 20 features from a single channel's data\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    \n",
    "# Time domain features\n",
    "    features.extend([\n",
    "        np.mean(channel_data),                    # 1. Mean\n",
    "        np.std(channel_data),                     # 2. Standard deviation\n",
    "        np.median(channel_data),                  # 3. Median\n",
    "        np.min(channel_data),                     # 4. Minimum\n",
    "        np.max(channel_data),                     # 5. Maximum\n",
    "        np.ptp(channel_data),                     # 6. Peak-to-peak\n",
    "        np.mean(np.abs(channel_data)),            # 7. Mean absolute value\n",
    "        stats.skew(channel_data),                 # 8. Skewness\n",
    "        stats.kurtosis(channel_data),             # 9. Kurtosis\n",
    "        np.sqrt(np.mean(channel_data**2)),        # 10. RMS\n",
    "    ])\n",
    "    \n",
    "# Frequnency domain features\n",
    "    freqs, psd = welch(channel_data, fs=sfreq, nperseg=min(256, len(channel_data)))\n",
    "    \n",
    "    # EEG frequency bands\n",
    "    bands = {\n",
    "        'delta': (0.5, 4),\n",
    "        'theta': (4, 8), \n",
    "        'alpha': (8, 13),\n",
    "        'beta': (13, 30),\n",
    "        'gamma': (30, 40)\n",
    "    }\n",
    "    \n",
    "    # Band power (11-15)\n",
    "    for band_name, (low_freq, high_freq) in bands.items():\n",
    "        band_mask = (freqs >= low_freq) & (freqs <= high_freq)\n",
    "        if np.any(band_mask):\n",
    "            band_power = np.sum(psd[band_mask])\n",
    "            features.append(band_power)\n",
    "        else:\n",
    "            features.append(0.0)\n",
    "    \n",
    "    # Spectral features (16-20)\n",
    "    features.extend([\n",
    "        np.mean(psd),                    # 16. Mean PSD\n",
    "        np.std(psd),                     # 17. Std PSD\n",
    "        np.median(psd),                  # 18. Median PSD\n",
    "        freqs[np.argmax(psd)],           # 19. Dominant frequency\n",
    "        np.max(psd),                     # 20. Maximum PSD\n",
    "    ])\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Run feature extraction for all subjects\n",
    "X, y = extract_features_all_subjects(base_data_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e0a9de",
   "metadata": {},
   "source": [
    "## Step 5: Data Aggregation and Normalization\n",
    "\n",
    "In this step, we aggregate the extracted features from all **109 subjects** into a single dataset to prepare for Deep Learning training.\n",
    "\n",
    "**Key Operations:**\n",
    "1. **Data Loading:** Iteratively loads `_features.npy` and `_labels.npy` for subjects `S001` to `S109`.\n",
    "2. **Concatenation:** Stacks all subject data into a unified feature matrix ($X$) and label vector ($y$).\n",
    "3. **Feature Scaling:** Applies **Standard Scaling** ($z = \\frac{x - \\mu}{\\sigma}$) to normalize features, ensuring stable model convergence.\n",
    "4. **Label Encoding:** Converts subject IDs into 0-indexed integers (0 to 108) using `LabelEncoder`.\n",
    "5. **Persistence:** Saves the normalized datasets and scaler artifacts to the `deep_learning_data/` directory for future inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfff4be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def combine_and_save_all_features(base_data_path, total_subjects=109):\n",
    "    \"\"\"\n",
    "    Load all 109 feature files, combine them, normalize, and save for DL\n",
    "    \"\"\"\n",
    "    features_dir = os.path.join(base_data_path, 'features_data')\n",
    "    dl_dir = os.path.join(base_data_path, 'deep_learning_data')\n",
    "    os.makedirs(dl_dir, exist_ok=True)\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Load all 109 feature files\n",
    "    for i in range(1, total_subjects + 1):\n",
    "        subject_name = f'S{i:03d}'\n",
    "        features_path = os.path.join(features_dir, f'{subject_name}_features.npy')\n",
    "        labels_path = os.path.join(features_dir, f'{subject_name}_labels.npy')\n",
    "        \n",
    "        print(f\"Loading {subject_name}...\")\n",
    "        \n",
    "        # Load features and labels for this subject\n",
    "        features = np.load(features_path)\n",
    "        labels = np.load(labels_path)\n",
    "        \n",
    "        all_features.append(features)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    # Combine all data\n",
    "    X = np.vstack(all_features)\n",
    "    y = np.hstack(all_labels)\n",
    "    # Feature Scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    # Label Encoding (1-109 → 0-108)\n",
    "    encoder = LabelEncoder()\n",
    "    y_encoded = encoder.fit_transform(y)\n",
    "    np.save(os.path.join(dl_dir, 'X_normalized.npy'), X_scaled)\n",
    "    np.save(os.path.join(dl_dir, 'y_encoded.npy'), y_encoded)\n",
    "    # Also save the scaler and encoder for future use\n",
    "    np.save(os.path.join(dl_dir, 'scaler_mean.npy'), scaler.mean_)\n",
    "    np.save(os.path.join(dl_dir, 'scaler_scale.npy'), scaler.scale_)\n",
    "    np.save(os.path.join(dl_dir, 'label_encoder_classes.npy'), encoder.classes_)\n",
    "    \n",
    "  \n",
    "    return X_scaled, y_encoded\n",
    "\n",
    "# Run it\n",
    "X_normalized, y_encoded = combine_and_save_all_features(base_data_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ab4f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
